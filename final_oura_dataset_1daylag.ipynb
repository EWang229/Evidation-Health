{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89774c7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "new_oura = pd.read_csv(\"C:/Users/rocke/Downloads/oura_sleep.csv\")  \n",
    "test_col = new_oura[\"bedtime_start\"].str[:10]  # taking in the date without time\n",
    "hour_col = new_oura[\"bedtime_start\"].str[11:13]  # extracting the time\n",
    "test_col_date = pd.to_datetime(test_col)  # converting to datetime, will be useful later\n",
    "test_col_date\n",
    "new_oura[\"bedtime_start\"] = test_col_date  # just creating columns for easier subsetting\n",
    "new_oura[\"bedtime_hour\"] = hour_col\n",
    "new_oura.rename(columns={\"bedtime_start\":\"date\"}, inplace=True)  # renaming for convenience\n",
    "new_oura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0532f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a column that tells you if the participant slept past midnight for that day, and if they started\n",
    "# to sleep during the day, I will drop them. note that times are listed in military time (ie. 0:00 - 24:00)\n",
    "past_midnight = []\n",
    "for i in new_oura[\"bedtime_hour\"]:\n",
    "    if int(i) < 5:\n",
    "        past_midnight.append(True)\n",
    "    elif 5 <= int(i) <= 18:\n",
    "        past_midnight.append(\"Drop\")\n",
    "    else:\n",
    "        past_midnight.append(False)\n",
    "new_oura[\"past_midnight\"] = past_midnight\n",
    "\n",
    "# admittedly, this won't account for people who nap before 5 am. (low chance, but possible. especially within a population of healthcare workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0b488",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dates = []\n",
    "import datetime as datetime\n",
    "for i in range(len(new_oura[\"bedtime_hour\"])):\n",
    "    if new_oura[\"past_midnight\"][i] == True:\n",
    "        # substract 1 if they slept past midnight, consistent with our method of lagging sleep by 1 day\n",
    "        new_day = new_oura[\"date\"][i] - datetime.timedelta(days=1) \n",
    "        new_dates.append(new_day)\n",
    "    else:\n",
    "        # change nothing to the date if they did not sleep past midnight\n",
    "        new_dates.append(new_oura[\"date\"][i])\n",
    "new_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ba490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_oura[\"date\"] = new_dates\n",
    "new_oura = new_oura[new_oura[\"past_midnight\"] != \"Drop\"]  # drop rows that had the value \"Drop\" in the past midnight thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b88b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rid of the weird sleepers (slept ONE time between 5 am and 6 pm, or slept for multiple days)\n",
    "sleep_duplicates = new_oura.duplicated(subset = [\"participant_id\", \"date\"], keep = \"last\")  # keep the LAST recorded sleep\n",
    "new_oura[\"sleep_duplicates\"] = sleep_duplicates\n",
    "new_oura = new_oura[new_oura[\"sleep_duplicates\"] == False]  # chooses the last row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d305ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking to see if there are any duplicate dates :)\n",
    "new_oura[[\"participant_id\", \"date\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94d6bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stress = pd.read_csv(\"C:/Users/rocke/Downloads/daily_stress_measure(2).csv\")\n",
    "stress_takedate = new_stress[\"daily858_startdate\"].str[:10]  # taking the date only\n",
    "stress_convertdate = pd.to_datetime(stress_takedate)  # converting to datetime, useful later for when we merge\n",
    "new_stress[\"daily858_startdate\"] = stress_convertdate\n",
    "new_stress.rename(columns={\"daily858_startdate\":\"date\"}, inplace=True)  # renaming\n",
    "new_stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac89ed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated = new_stress.duplicated(subset = [\"participant_id\", \"date\"], keep = \"last\")  # taking only the last recorded survey response\n",
    "new_stress[\"duplicated\"] = duplicated\n",
    "new_stress = new_stress[new_stress[\"duplicated\"] == False]\n",
    "new_stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4e7044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shifting each sleep variable DOWN by 1 day for EACH participant. Why? Naively shifting the whole data set means we are assuming we are only working with one participant\n",
    "new_oura[['awake', 'bedtime_end', 'bedtime_end_delta', 'date',\n",
    "       'bedtime_start_delta', 'breath_average', 'deep', 'duration',\n",
    "       'efficiency', 'hr_5min', 'hr_average', 'hr_lowest', 'hypnogram_5min',\n",
    "       'is_longest', 'light', 'midpoint_at_delta', 'midpoint_time',\n",
    "       'onset_latency', 'period_id', 'rem', 'restless', 'rmssd', 'rmssd_5min',\n",
    "       'score', 'score_alignment', 'score_deep', 'score_disturbances',\n",
    "       'score_efficiency', 'score_latency', 'score_rem', 'score_total',\n",
    "       'summary_date', 'temperature_delta', 'temperature_deviation',\n",
    "       'temperature_trend_deviation', 'total']] = new_oura.groupby(['participant_id'])['awake', 'bedtime_end', 'bedtime_end_delta', 'date',\n",
    "       'bedtime_start_delta', 'breath_average', 'deep', 'duration',\n",
    "       'efficiency', 'hr_5min', 'hr_average', 'hr_lowest', 'hypnogram_5min',\n",
    "       'is_longest', 'light', 'midpoint_at_delta', 'midpoint_time',\n",
    "       'onset_latency', 'period_id', 'rem', 'restless', 'rmssd', 'rmssd_5min',\n",
    "       'score', 'score_alignment', 'score_deep', 'score_disturbances',\n",
    "       'score_efficiency', 'score_latency', 'score_rem', 'score_total',\n",
    "       'summary_date', 'temperature_delta', 'temperature_deviation',\n",
    "       'temperature_trend_deviation', 'total'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3f5db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_oura = new_oura[new_oura[\"score\"].notnull()]  # taking away the nan's produced by shifting \n",
    "new_oura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f95a7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_tables = pd.merge(new_oura, new_stress, how = \"left\", on = \"participant_id\")  # left merge on participant id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba16db0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_merge_table = merged_tables[merged_tables[\"date_x\"] == merged_tables[\"date_y\"]]  # then selecting by dates\n",
    "\n",
    "# here, we managed to have each observation unique by its date and participant id\n",
    "final_merge_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since there are 3 columns for working with covid, I made this binary. Shouldn't matter much if someone worked with covid\n",
    "# earlier or later in their shift (assumption)\n",
    "work_with_covid = [] \n",
    "for i in range(len(final_merge_table[\"daily_covid_shifts___1\"])):\n",
    "    if (final_merge_table[\"daily_covid_shifts___1\"].iloc[i] == 0) and (final_merge_table[\"daily_covid_shifts___2\"].iloc[i] == 0):\n",
    "        work_with_covid.append(0)\n",
    "    else:\n",
    "        work_with_covid.append(1)\n",
    "final_merge_table[\"worked_with_covid\"] = work_with_covid\n",
    "final_merge_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5a70b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure there are no duplicates after the merge\n",
    "final_merge_table[[\"participant_id\", \"date_x\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61390a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merging ptsd survey data with our data set\n",
    "ptsd = pd.read_csv(\"C:/Users/rocke/Downloads/ptsd_checklist_pclc.csv\")\n",
    "ptsd_merge = pd.merge(final_merge_table, ptsd, how = \"inner\", on = \"participant_id\")\n",
    "ptsd_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6abccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the ace survey data set\n",
    "ace_survey = pd.read_csv(\"C:/Users/rocke/Downloads/adverse_childhood_events_ace.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3b0815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now mering ace with our updated data set as well\n",
    "ace_ptsd_merge = pd.merge(ptsd_merge, ace_survey, how = \"inner\", on = \"participant_id\")\n",
    "ace_ptsd_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4867c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the demographics data set\n",
    "dem = pd.read_csv(\"C:/Users/rocke/Downloads/demographics_survey(1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757bdc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, merging demographic survey data to our updated data set\n",
    "oura1lag_dem = pd.merge(ace_ptsd_merge, dem, how = \"left\", on = \"participant_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd343c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beautiful.\n",
    "oura1lag_dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451dd2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving final data set as a csv for easy use/access\n",
    "oura1lag_dem.to_csv(\"C:/Users/rocke/Downloads/updated_oura_stress_ptsd_ace_1lag.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
