{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0952a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run, reading in files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "oura_2lag = pd.read_csv(\"C:/Users/rocke/Downloads/oura_stress_data/oura_stress_ptsd_ace_2lag.csv\")\n",
    "X = oura_2lag.loc[:, oura_2lag.columns != \"daily_stressed\"]\n",
    "y = oura_2lag[[\"daily_stressed\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6216e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore this\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, \n",
    "                                                    random_state = 10, stratify = X[\"participant_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca76dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to get sum of pcl\n",
    "pcl_sum = []\n",
    "for i in range(len(oura_2lag)):\n",
    "    pcl = 0\n",
    "    for j in range(1, 18):\n",
    "        pcl += oura_2lag[\"pcl_\" + str(j)][i]  # just a clever way to get the sum of all pcl columns\n",
    "    pcl_sum.append(pcl)\n",
    "pcl_sum\n",
    "oura_2lag[\"pcl_sum\"] = pcl_sum  # adding in column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc69854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to get sum of ace\n",
    "ace_sum = []\n",
    "for i in range(len(oura_2lag)):\n",
    "    ace = 0\n",
    "    for j in range(1, 11):\n",
    "        ace += oura_2lag[\"ace_\" + str(j)][i]  # just a clever way to get teh sum of all ace columns\n",
    "    ace_sum.append(ace)\n",
    "ace_sum\n",
    "oura_2lag[\"ace_sum\"] = ace_sum  # adding in column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b1d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore, just testing out smf\n",
    "import statsmodels.formula.api as smf\n",
    "log_reg = smf.logit(formula = \"daily_stressed ~ pcl_1\", data = oura_2lag).fit_regularized(method = \"l1\")\n",
    "print(log_reg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c4e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run. standardizes and splits into training and testing data. return 3 objects. summary, confusion matrix, and accuracy\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, ConfusionMatrixDisplay)\n",
    "from sklearn.model_selection import train_test_split\n",
    "def logit_ftn(predictors, target, data1):\n",
    "    copy = data1.copy()  # making a copy of the original dataframe. don't want to mess with original data\n",
    "    empty = \"\"  # empty string used later for formula argument inside logit()\n",
    "    predictor_list = []  # empty list for predictors for subsetting\n",
    "    for i in predictors:\n",
    "        predictor_list.append(i)\n",
    "    for i in predictor_list:\n",
    "        copy[i] = (copy[i] - copy[i].mean()) / copy[i].std()\n",
    "    for i in predictors:\n",
    "        empty += i + \" + \"\n",
    "    empty = empty[:-3]  # erases the \" + \"\n",
    "    eqn = target + \"~\" + empty  # formula equation\n",
    "    log_reg = smf.logit(formula = eqn, data = copy).fit()\n",
    "    predictor_list.append(\"participant_id\")  # adding this here now because it was not necessary to scale participant_id\n",
    "    X = copy.loc[:, predictor_list]\n",
    "    y = copy[[\"daily_stressed\"]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, \n",
    "                                                    random_state = 10, stratify = X[\"participant_id\"])\n",
    "    yhat = log_reg.predict(X_test)  # getting the prediction values\n",
    "    prediction = []\n",
    "    for i in yhat:\n",
    "        if i <= 0.3:\n",
    "            prediction.append(0)\n",
    "        else:\n",
    "            prediction.append(1)\n",
    "    cm = confusion_matrix(y_test, prediction)  # confustion matrix\n",
    "    accuracy = accuracy_score(y_test, prediction)  # gives the accuracy on testing data\n",
    "    return log_reg.summary(), cm, accuracy  # returns a list of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a539513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running to see if it works\n",
    "summary, cm, accuracy = logit_ftn([\"duration\", \"pcl_1\", \"pcl_2\", \"pcl_3\"], \"daily_stressed\", oura_2lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking out the model\n",
    "print(summary)\n",
    "print(cm)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f65d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input a threshold start, stop, and step interval... as well as predictors, target variable, and dataframe. returns\n",
    "# threshold value, confusion matrix, and plots ROC curve\n",
    "\n",
    "# wanted to find an \"optimal\" threshold value. it is important to note that for different scenarios/goals, \"optimal\" may \n",
    "# have different definitions. revelation came thanks to Dr. Franks. \n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "def best_acc_model(start, stop, step, predictors, target, data1):\n",
    "    rates = []\n",
    "    for t in np.arange(start, stop, step):\n",
    "        copy = data1.copy()  # making a copy of the original dataframe. don't want to mess with original data\n",
    "        empty = \"\"  # empty string used later for formula argument inside logit()\n",
    "        predictor_list = []  # empty list for predictors for subsetting\n",
    "        for i in predictors:\n",
    "            predictor_list.append(i)\n",
    "        for i in predictor_list:\n",
    "            copy[i] = (copy[i] - copy[i].mean()) / copy[i].std()\n",
    "        for i in predictors:\n",
    "            empty += i + \" + \"\n",
    "        empty = empty[:-3]  # erases the \" + \"\n",
    "        eqn = target + \"~\" + empty  # formula equation\n",
    "        log_reg = smf.logit(formula = eqn, data = copy).fit()\n",
    "        predictor_list.append(\"participant_id\")  # adding this here now because it was not necessary to scale participant_id\n",
    "        X = copy.loc[:, predictor_list]\n",
    "        y = copy[[\"daily_stressed\"]]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, \n",
    "                                                        random_state = 10, stratify = X[\"participant_id\"])\n",
    "        yhat = log_reg.predict(X_test)  # getting the prediction values of probabilities\n",
    "        fpr, tpr, _ = metrics.roc_curve(y_test,  yhat)\n",
    "        prediction = []\n",
    "        for i in yhat:\n",
    "            if i <= t:\n",
    "                prediction.append(0)\n",
    "            else:\n",
    "                prediction.append(1)\n",
    "        cm = confusion_matrix(y_test, prediction)\n",
    "        cm_list.append(cm)\n",
    "        accuracy = accuracy_score(y_test, prediction)\n",
    "        print(\"Threshold value:\", t, \"and accuracy:\", accuracy)\n",
    "        print(cm)\n",
    "        plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8476e89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing the function\n",
    "best_acc_model(0.2, 0.9, 0.01, [\"daily_shifts\", \"worked_with_covid\", \"restless\", \"score\"], \"daily_stressed\", oura_2lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2d6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing out my *first* function on this subset\n",
    "summary, cm, accuracy = logit_ftn([\"score\", \"daily_shifts\", \"worked_with_covid\", \"restless\"], \"daily_stressed\", oura_2lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b4f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary)  # works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62433a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)  # works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a58d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "oura_2lag[\"participant_id\"].value_counts()\n",
    "\n",
    "# could it be that a participant(s) is always stressed or never stressed? means that the variable will be perfectly\n",
    "# correlated to the response. \n",
    "\n",
    "for i in oura_2lag[\"participant_id\"].unique():\n",
    "    yes = oura_2lag[oura_2lag[\"participant_id\"] == i][\"daily_stressed\"].value_counts()\n",
    "    if len(yes) == 1:\n",
    "        print(i)\n",
    "        \n",
    "# there are some participants who are always stress/no stressed, found after running the above for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b3a12c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# just taking away these participants. allows the logit model to run\n",
    "test = copy[\"participant_id\"].isin([\"U-5HZ8AMM58QDLR5JZV2NL\", \"U-ATEES286BB2TCX95R9T3\", \"U-JA3NXGB6CL1W7CZGH5MA\", \n",
    "                                    \"U-L8KA5ZY6HBEEQJ2W7C6V\", \"U-NCR7YC8J7R151B5XUHYT\", \"U-U9C8WE1MNK1SC43YZYMP\",\n",
    "                                    \"U-URPG7EFR92D8CQP36S52\", \"U-Z6KKZKWG52EQAEDPPAVR\"])\n",
    "copy = copy[~test]\n",
    "copy\n",
    "\n",
    "# this block ended up being useless since I utilized regularization. this means coefficients won't blow up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c002b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = copy[\"participant_id\"].isin([\"U-5HZ8AMM58QDLR5JZV2NL\", \"U-ATEES286BB2TCX95R9T3\", \"U-JA3NXGB6CL1W7CZGH5MA\", \n",
    "                                    \"U-L8KA5ZY6HBEEQJ2W7C6V\", \"U-NCR7YC8J7R151B5XUHYT\", \"U-U9C8WE1MNK1SC43YZYMP\",\n",
    "                                    \"U-URPG7EFR92D8CQP36S52\", \"U-Z6KKZKWG52EQAEDPPAVR\"])\n",
    "copy = copy[~test]\n",
    "\n",
    "predictor_standardize = [\"restless\", \"duration\", \"score\", \"ace_sum\", \"pcl_sum\"]\n",
    "for i in predictor_standardize:\n",
    "    copy[i] = (copy[i] - copy[i].mean()) / copy[i].std()\n",
    "log_reg = smf.logit(formula = \"daily_stressed ~ daily_shifts + worked_with_covid + score*restless + score*duration + pcl_sum + ace_sum\", \n",
    "                    data = copy).fit()\n",
    "print(log_reg.summary())\n",
    "X = copy.loc[:, copy.columns != \"daily_stressed\"]\n",
    "y = copy[[\"daily_stressed\"]]\n",
    "yhat = log_reg.predict(X)\n",
    "fpr, tpr, _ = metrics.roc_curve(y,  yhat)\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc3180e8",
   "metadata": {},
   "source": [
    "Going to check my models without participant id, with participant id, and only participant id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed172ba3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# WITHOUT participant id\n",
    "copy = oura_2lag.copy()\n",
    "'''test = copy[\"participant_id\"].isin([\"U-5HZ8AMM58QDLR5JZV2NL\", \"U-ATEES286BB2TCX95R9T3\", \"U-JA3NXGB6CL1W7CZGH5MA\", \n",
    "                                    \"U-L8KA5ZY6HBEEQJ2W7C6V\", \"U-NCR7YC8J7R151B5XUHYT\", \"U-U9C8WE1MNK1SC43YZYMP\",\n",
    "                                    \"U-URPG7EFR92D8CQP36S52\", \"U-Z6KKZKWG52EQAEDPPAVR\"])'''\n",
    "#copy = copy[~test]\n",
    "predictor_standardize = [\"restless\", \"duration\", \"score\", \"ace_sum\", \"pcl_sum\"]\n",
    "for i in predictor_standardize:\n",
    "    copy[i] = (copy[i] - copy[i].mean()) / copy[i].std()\n",
    "log_reg = smf.logit(formula = \"daily_stressed ~ daily_shifts + worked_with_covid + score*restless + score*duration + pcl_sum + ace_sum\", \n",
    "                    data = copy).fit()\n",
    "print(log_reg.summary())\n",
    "X = copy.loc[:, copy.columns != \"daily_stressed\"]\n",
    "y = copy[[\"daily_stressed\"]]\n",
    "yhat = log_reg.predict(X)\n",
    "fpr, tpr, _ = metrics.roc_curve(y,  yhat)\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf8018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY participant id\n",
    "copy = oura_2lag.copy()\n",
    "'''test = copy[\"participant_id\"].isin([\"U-5HZ8AMM58QDLR5JZV2NL\", \"U-ATEES286BB2TCX95R9T3\", \"U-JA3NXGB6CL1W7CZGH5MA\", \n",
    "                                    \"U-L8KA5ZY6HBEEQJ2W7C6V\", \"U-NCR7YC8J7R151B5XUHYT\", \"U-U9C8WE1MNK1SC43YZYMP\",\n",
    "                                    \"U-URPG7EFR92D8CQP36S52\", \"U-Z6KKZKWG52EQAEDPPAVR\"])'''\n",
    "#copy = copy[~test]\n",
    "predictor_standardize = [\"restless\", \"duration\", \"score\", \"ace_sum\", \"pcl_sum\"]\n",
    "for i in predictor_standardize:\n",
    "    copy[i] = (copy[i] - copy[i].mean()) / copy[i].std()\n",
    "log_reg = smf.logit(formula = \"daily_stressed ~ C(participant_id)\", \n",
    "                    data = copy).fit_regularized(method = \"l1\")\n",
    "print(log_reg.summary())\n",
    "X = copy.loc[:, copy.columns != \"daily_stressed\"]\n",
    "y = copy[[\"daily_stressed\"]]\n",
    "yhat = log_reg.predict(X)\n",
    "fpr, tpr, _ = metrics.roc_curve(y,  yhat)\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11624d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at how many days per subject. smaller numbers can affect their probability greatly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec1e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(copy[\"pcl_sum\"])/len(copy[\"pcl_sum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81115fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOTH participant id and features\n",
    "copy = oura_2lag.copy()\n",
    "predictor_standardize = [\"restless\", \"duration\", \"score\", \"pcl_sum\", \"ace_sum\"]\n",
    "for i in predictor_standardize:\n",
    "    copy[i] = (copy[i] - copy[i].mean()) / copy[i].std()\n",
    "log_reg = smf.logit(formula = \"daily_stressed ~ C(participant_id) + daily_shifts + worked_with_covid + score*restless + score*duration\", \n",
    "                    data = copy).fit_regularized(method = \"l1\")\n",
    "print(log_reg.summary())\n",
    "X = copy.loc[:, copy.columns != \"daily_stressed\"]\n",
    "y = copy[[\"daily_stressed\"]]\n",
    "yhat = log_reg.predict(X)\n",
    "fpr, tpr, _ = metrics.roc_curve(y,  yhat)\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "# collinearity, brute force method. look up a package for multicollinearity. no reg. in mixed effects. might be because\n",
    "# we don't care about coefficient in mixed effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017cf2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOTH participant id and features\n",
    "copy = oura_2lag.copy()\n",
    "predictor_standardize = [\"restless\", \"duration\", \"score\", \"pcl_sum\", \"ace_sum\"]\n",
    "for i in predictor_standardize:\n",
    "    copy[i] = (copy[i] - copy[i].mean()) / copy[i].std()\n",
    "print(copy)\n",
    "'''log_reg = smf.mixedlm(formula = \"daily_stressed ~ daily_shifts + worked_with_covid + score\", \n",
    "                    data = copy, groups = copy[\"participant_id\"]).fit(method=[\"lbfgs\"])\n",
    "print(log_reg.summary())\n",
    "X = copy.loc[:, copy.columns != \"daily_stressed\"]\n",
    "y = copy[[\"daily_stressed\"]]\n",
    "yhat = log_reg.predict(X)\n",
    "fpr, tpr, _ = metrics.roc_curve(y,  yhat)\n",
    "plt.plot(fpr, tpr)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad2381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe try plotting precision vs recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098c9dca",
   "metadata": {},
   "source": [
    "***CAN IGNORE EVERYTHING TO THE BOTTOM OF THIS, JUST LOOKING AT SOME VARIABLES***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8cc123",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcl = X_train[X_train.columns[pd.Series(X_train.columns).str.startswith('pcl_')]]  # choosing all PTSD vars\n",
    "ace = X_train[X_train.columns[pd.Series(X_train.columns).str.startswith('ace_')]]  # choosing all ACE vars\n",
    "pcl_ace = pd.concat([pcl, ace], axis = 1)  # combining both PTSD and ACE vars\n",
    "pcl_ace = pcl_ace.loc[:, pcl_ace.columns != \"ace_ts\"]  # dropping ace_ts\n",
    "pcl_ace\n",
    "X_train_pcl_ace = pcl_ace  # renaming (I don't follow this convention for other training sets later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a5fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "log_reg = sm.Logit(y_train, X_train_pcl_ace).fit()  # fitting a logistic regression\n",
    "print(log_reg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1f623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of this is for the testing data to match training data parameters\n",
    "pcl_test = X_test[X_test.columns[pd.Series(X_test.columns).str.startswith('pcl_')]] \n",
    "ace_test = X_test[X_test.columns[pd.Series(X_test.columns).str.startswith('ace_')]]\n",
    "pcl_ace_test = pd.concat([pcl_test, ace_test], axis = 1)\n",
    "pcl_ace_test = pcl_ace_test.loc[:, pcl_ace_test.columns != \"ace_ts\"]\n",
    "X_test_pcl_ace = pcl_ace_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc41a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (confusion_matrix, accuracy_score, ConfusionMatrixDisplay)\n",
    "\n",
    "# confusion matrix and performance matrix of ACE and PTSD vars\n",
    "yhat = log_reg.predict(X_test_pcl_ace)\n",
    "prediction = list(map(round, yhat))\n",
    "cm = confusion_matrix(y_test, prediction)\n",
    "print (\"Confusion Matrix : \\n\", cm)\n",
    " \n",
    "# accuracy score of the model\n",
    "print('Test accuracy = ', accuracy_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aa6c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "\n",
    "# confusion matrix with ACE and PTSD included\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fb9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating different subsets of variables to use\n",
    "covid = X_train[[\"worked_with_covid\"]]\n",
    "sleep = X_train[[\"score\"]]\n",
    "covid_test = X_test[[\"worked_with_covid\"]]\n",
    "sleep_test = X_test[[\"score\"]]\n",
    "pcl_ace_covid = pd.concat([pcl_ace, covid], axis = 1)\n",
    "pcl_ace_sleep = pd.concat([pcl_ace, sleep], axis = 1)\n",
    "pcl_ace_covid_sleep = pd.concat([pcl_ace_covid, sleep], axis = 1)\n",
    "covid_sleep = pd.concat([covid, sleep], axis = 1)\n",
    "\n",
    "# testing portion\n",
    "pcl_ace_covid_test = pd.concat([pcl_ace_test, covid_test], axis = 1)\n",
    "pcl_ace_sleep_test = pd.concat([pcl_ace_test, sleep_test], axis = 1)\n",
    "pcl_ace_covid_sleep_test = pd.concat([pcl_ace_covid_test, sleep_test], axis = 1)\n",
    "covid_sleep_test = pd.concat([covid_test, sleep_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92abee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting some more models\n",
    "log_reg2 = sm.Logit(y_train, pcl_ace_covid).fit()  # PTSD, ACE, and WORK w/ COVID\n",
    "log_reg3 = sm.Logit(y_train, pcl_ace_sleep).fit()  # PTSD, ACE, AND SLEEP SCORE\n",
    "log_reg4 = sm.Logit(y_train, pcl_ace_covid_sleep).fit()  # PTSD, ACE, WORK w/ COVID, AND SLEEP SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690a29f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PTSD, ACE, and WORK W/ COVID\n",
    "yhat2 = log_reg2.predict(pcl_ace_covid_test)\n",
    "prediction2 = list(map(round, yhat2))\n",
    "cm2 = confusion_matrix(y_test, prediction2)\n",
    "print (\"Confusion Matrix : \\n\", cm2)\n",
    " \n",
    "# accuracy score of the model\n",
    "print('Test accuracy = ', accuracy_score(y_test, prediction2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8cd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm2)\n",
    "disp2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e672d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PTSD, ACE, AND SLEEP SCORE\n",
    "yhat3 = log_reg3.predict(pcl_ace_sleep_test)\n",
    "prediction3 = list(map(round, yhat3))\n",
    "cm3 = confusion_matrix(y_test, prediction3)\n",
    "print (\"Confusion Matrix : \\n\", cm3)\n",
    " \n",
    "# accuracy score of the model\n",
    "print('Test accuracy = ', accuracy_score(y_test, prediction3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51d6cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp3 = ConfusionMatrixDisplay(confusion_matrix=cm3)\n",
    "disp3.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db461cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PTSD, ACE, WORK w/ COVID, and SLEEP SCORE\n",
    "yhat4 = log_reg4.predict(pcl_ace_covid_sleep_test)\n",
    "prediction4 = list(map(round, yhat4))\n",
    "cm4 = confusion_matrix(y_test, prediction4)\n",
    "print (\"Confusion Matrix : \\n\", cm4)\n",
    " \n",
    "# accuracy score of the model\n",
    "print('Test accuracy = ', accuracy_score(y_test, prediction4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e877802",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp4 = ConfusionMatrixDisplay(confusion_matrix=cm4)\n",
    "disp4.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6eab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f32df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting more models\n",
    "log_reg5 = sm.Logit(y_train, covid).fit()  # just work w/ covid\n",
    "log_reg6 = sm.Logit(y_train, sleep).fit()  # just sleep score\n",
    "log_reg7 = sm.Logit(y_train, covid_sleep).fit()  # just covid and sleep score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d14c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORK w/ COVID\n",
    "yhat5 = log_reg5.predict(covid_test)\n",
    "prediction5 = list(map(round, yhat5))\n",
    "cm5 = confusion_matrix(y_test, prediction5)\n",
    "print (\"Confusion Matrix : \\n\", cm5)\n",
    " \n",
    "# accuracy score of the model\n",
    "print('Test accuracy = ', accuracy_score(y_test, prediction5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLEEP SCORE\n",
    "yhat6 = log_reg6.predict(sleep_test)\n",
    "prediction6 = list(map(round, yhat6))\n",
    "cm6 = confusion_matrix(y_test, prediction6)\n",
    "print (\"Confusion Matrix : \\n\", cm6)\n",
    " \n",
    "# accuracy score of the model\n",
    "print('Test accuracy = ', accuracy_score(y_test, prediction6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORK w/ COVID AND SLEEP SCORE\n",
    "yhat7 = log_reg7.predict(covid_sleep_test)\n",
    "prediction7 = list(map(round, yhat7))\n",
    "cm7 = confusion_matrix(y_test, prediction7)\n",
    "print (\"Confusion Matrix : \\n\", cm7)\n",
    " \n",
    "# accuracy score of the model\n",
    "print('Test accuracy = ', accuracy_score(y_test, prediction7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc3cb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_reg2.summary())\n",
    "print(log_reg3.summary())\n",
    "print(log_reg4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9090d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_reg5.summary())\n",
    "print(log_reg6.summary())\n",
    "print(log_reg7.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d723e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = oura_2lag.copy()\n",
    "test = copy[\"participant_id\"].isin([\"U-5HZ8AMM58QDLR5JZV2NL\", \"U-ATEES286BB2TCX95R9T3\", \"U-JA3NXGB6CL1W7CZGH5MA\", \n",
    "                                    \"U-L8KA5ZY6HBEEQJ2W7C6V\", \"U-NCR7YC8J7R151B5XUHYT\", \"U-U9C8WE1MNK1SC43YZYMP\",\n",
    "                                    \"U-URPG7EFR92D8CQP36S52\", \"U-Z6KKZKWG52EQAEDPPAVR\"])\n",
    "copy = copy[~test]\n",
    "\n",
    "mixed_oura = smf.mixedlm(\"daily_stressed ~ worked_with_covid + daily_shifts + pcl_sum + ace_sum\", oura_2lag, groups = oura_2lag[\"participant_id\"])\n",
    "mixed_oura_fit = mixed_oura.fit()\n",
    "mixed_oura_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c8abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "oura_2lag[\"pcl_sum\"].nunique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
